{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Add as keras_add_layers\n",
    "from keras.callbacks import History\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static letter variable\n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "sequence_length = 10\n",
    "\n",
    "# Generates a random sequence of letters\n",
    "def generate_random_sequence_of_letters(length=sequence_length):\n",
    "    sequence = ''\n",
    "    for _ in range(length):\n",
    "        sequence += letters[rand.randint(0,len(letters) - 1)]\n",
    "    return sequence\n",
    "\n",
    "# Shifts the letters in a sequence by the specified amount\n",
    "def shift_sequence(sequence,shift_size=rand.randint(0,len(letters) - 2)):\n",
    "    ret_sequence = ''\n",
    "    for letter in sequence:\n",
    "        index = letters.index(letter)\n",
    "        index += shift_size\n",
    "        while index > len(letters) - 1:\n",
    "            index -= len(letters)\n",
    "        ret_sequence += letters[index]\n",
    "    return ret_sequence\n",
    "            \n",
    "# Converts a sequence of letters into an index vector\n",
    "def convert_to_index_vector(sequence):\n",
    "    ret_vector = []\n",
    "    for letter in sequence:\n",
    "        ret_vector.append(float(letters.index(letter)))\n",
    "    return ret_vector\n",
    "\n",
    "number_of_scrambled_sequences = 10\n",
    "# Generates the scrambled inputs for a given sequence\n",
    "def generate_scrambled_inputs(sequence):\n",
    "    input_vector = []\n",
    "    for i in range(number_of_scrambled_sequences):\n",
    "        input_vector += convert_to_index_vector(shift_sequence(sequence,shift_size=i + 1))\n",
    "    return input_vector\n",
    "\n",
    "# Generates training data\n",
    "def generate_training_data(size=10000):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for _ in range(size):\n",
    "        sequence = generate_random_sequence_of_letters()\n",
    "        outputs.append(convert_to_index_vector(sequence))\n",
    "        inputs.append(generate_scrambled_inputs(sequence))\n",
    "    return [np.array(inputs),np.array(outputs)]\n",
    "\n",
    "# Converts an index vector to a string\n",
    "def convert_index_vector(index_vector):\n",
    "    sequence = ''\n",
    "    for index in index_vector:\n",
    "        if round(index) < len(letters):\n",
    "            sequence += letters[int(round(index))]\n",
    "        else:\n",
    "            sequence += '*'\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(80,activation=\"sigmoid\",input_dim=number_of_scrambled_sequences*sequence_length))\n",
    "model.add(Dense(40,activation=\"sigmoid\"))\n",
    "model.add(Dense(20,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"linear\"))\n",
    "model.compile(optimizer=\"adam\",loss=\"mean_absolute_percentage_error\",metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 4600443.1765 - mean_absolute_error: 12.4469 - val_loss: 412117.7785 - val_mean_absolute_error: 12.5097\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 216464.3258 - mean_absolute_error: 12.4613 - val_loss: 169554.6663 - val_mean_absolute_error: 12.5128\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 153280.9062 - mean_absolute_error: 12.4615 - val_loss: 228256.9701 - val_mean_absolute_error: 12.5063\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 179542.5741 - mean_absolute_error: 12.4612 - val_loss: 135929.7479 - val_mean_absolute_error: 12.5110\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 117606.9546 - mean_absolute_error: 12.4615 - val_loss: 98088.8148 - val_mean_absolute_error: 12.5093\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 117180.7402 - mean_absolute_error: 12.4614 - val_loss: 146086.6665 - val_mean_absolute_error: 12.5074\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 112746.1941 - mean_absolute_error: 12.4614 - val_loss: 149021.5089 - val_mean_absolute_error: 12.5108\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 147251.1494 - mean_absolute_error: 12.4614 - val_loss: 106491.8680 - val_mean_absolute_error: 12.5084\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 138961.9391 - mean_absolute_error: 12.4614 - val_loss: 147822.0972 - val_mean_absolute_error: 12.5088\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 142473.9336 - mean_absolute_error: 12.4613 - val_loss: 90211.0610 - val_mean_absolute_error: 12.5088\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 115192.8062 - mean_absolute_error: 12.4612 - val_loss: 79825.9195 - val_mean_absolute_error: 12.5095\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 111972.5623 - mean_absolute_error: 12.4614 - val_loss: 148078.0120 - val_mean_absolute_error: 12.5085\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 134429.9380 - mean_absolute_error: 12.4613 - val_loss: 125654.8792 - val_mean_absolute_error: 12.5108\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 133058.2686 - mean_absolute_error: 12.4612 - val_loss: 99707.0450 - val_mean_absolute_error: 12.5109\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 147226.2391 - mean_absolute_error: 12.4613 - val_loss: 101233.2504 - val_mean_absolute_error: 12.5080\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 134386.7095 - mean_absolute_error: 12.4612 - val_loss: 161886.5641 - val_mean_absolute_error: 12.5114\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 90117.6280 - mean_absolute_error: 12.4614 - val_loss: 66650.8660 - val_mean_absolute_error: 12.5097\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 98350.1079 - mean_absolute_error: 12.4611 - val_loss: 106074.7877 - val_mean_absolute_error: 12.5091\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 94008.7847 - mean_absolute_error: 12.4612 - val_loss: 82609.0199 - val_mean_absolute_error: 12.5098\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 99798.1622 - mean_absolute_error: 12.4612 - val_loss: 150185.0377 - val_mean_absolute_error: 12.5099\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 134651.7500 - mean_absolute_error: 12.4614 - val_loss: 107223.6554 - val_mean_absolute_error: 12.5089\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 133324.6190 - mean_absolute_error: 12.4615 - val_loss: 151178.4078 - val_mean_absolute_error: 12.5089\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 155132.1965 - mean_absolute_error: 12.4617 - val_loss: 127868.7337 - val_mean_absolute_error: 12.5087\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 125508.3214 - mean_absolute_error: 12.4612 - val_loss: 96825.8731 - val_mean_absolute_error: 12.5105\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 90008.4046 - mean_absolute_error: 12.4610 - val_loss: 70737.2012 - val_mean_absolute_error: 12.5104\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 109726.0461 - mean_absolute_error: 12.4613 - val_loss: 95798.1389 - val_mean_absolute_error: 12.5100\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 103015.1228 - mean_absolute_error: 12.4613 - val_loss: 107511.2085 - val_mean_absolute_error: 12.5088\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 101798.9444 - mean_absolute_error: 12.4611 - val_loss: 124448.2190 - val_mean_absolute_error: 12.5091\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 96891.9579 - mean_absolute_error: 12.4612 - val_loss: 88864.1941 - val_mean_absolute_error: 12.5096\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 103178.3732 - mean_absolute_error: 12.4613 - val_loss: 105778.3021 - val_mean_absolute_error: 12.5090\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 127067.7580 - mean_absolute_error: 12.4614 - val_loss: 66888.5936 - val_mean_absolute_error: 12.5102\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 90886.1737 - mean_absolute_error: 12.4612 - val_loss: 76810.6324 - val_mean_absolute_error: 12.5104\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 88099.6180 - mean_absolute_error: 12.4614 - val_loss: 112476.3716 - val_mean_absolute_error: 12.5088\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 106657.0795 - mean_absolute_error: 12.4613 - val_loss: 95890.2362 - val_mean_absolute_error: 12.5112\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 103112.6398 - mean_absolute_error: 12.4612 - val_loss: 101457.1411 - val_mean_absolute_error: 12.5110\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 111749.9440 - mean_absolute_error: 12.4613 - val_loss: 92994.0391 - val_mean_absolute_error: 12.5094\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 127310.4164 - mean_absolute_error: 12.4612 - val_loss: 127086.6927 - val_mean_absolute_error: 12.5098\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 116769.6049 - mean_absolute_error: 12.4611 - val_loss: 75858.6730 - val_mean_absolute_error: 12.5099\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 101708.7276 - mean_absolute_error: 12.4614 - val_loss: 121144.2926 - val_mean_absolute_error: 12.5083\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 137997.1761 - mean_absolute_error: 12.4615 - val_loss: 106586.7574 - val_mean_absolute_error: 12.5103\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 112377.1519 - mean_absolute_error: 12.4614 - val_loss: 96035.8227 - val_mean_absolute_error: 12.5101\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 96173.9127 - mean_absolute_error: 12.4614 - val_loss: 97993.1061 - val_mean_absolute_error: 12.5086\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 106223.1778 - mean_absolute_error: 12.4612 - val_loss: 57410.6254 - val_mean_absolute_error: 12.5099\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 94576.8744 - mean_absolute_error: 12.4614 - val_loss: 85968.5995 - val_mean_absolute_error: 12.5080\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 105304.8670 - mean_absolute_error: 12.4612 - val_loss: 102609.5196 - val_mean_absolute_error: 12.5097\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 9us/step - loss: 110294.9175 - mean_absolute_error: 12.4614 - val_loss: 89048.5514 - val_mean_absolute_error: 12.5096\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 88034.6252 - mean_absolute_error: 12.4612 - val_loss: 59426.7224 - val_mean_absolute_error: 12.5097\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 87659.7662 - mean_absolute_error: 12.4611 - val_loss: 107528.0660 - val_mean_absolute_error: 12.5105\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 116110.1610 - mean_absolute_error: 12.4613 - val_loss: 118342.7673 - val_mean_absolute_error: 12.5092\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 94409.1735 - mean_absolute_error: 12.4613 - val_loss: 103088.9261 - val_mean_absolute_error: 12.5108\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 102172.8794 - mean_absolute_error: 12.4617 - val_loss: 147203.9225 - val_mean_absolute_error: 12.5101\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 103814.3291 - mean_absolute_error: 12.4612 - val_loss: 143959.6369 - val_mean_absolute_error: 12.5097\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 105228.6529 - mean_absolute_error: 12.4613 - val_loss: 194283.9593 - val_mean_absolute_error: 12.5116\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 165100.8864 - mean_absolute_error: 12.4615 - val_loss: 115263.0835 - val_mean_absolute_error: 12.5092\n",
      "Epoch 55/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 106410.6545 - mean_absolute_error: 12.4612 - val_loss: 107186.5256 - val_mean_absolute_error: 12.5117\n",
      "Epoch 56/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 92763.2675 - mean_absolute_error: 12.4613 - val_loss: 117685.4949 - val_mean_absolute_error: 12.5090\n",
      "Epoch 57/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 98397.8377 - mean_absolute_error: 12.4613 - val_loss: 132146.7711 - val_mean_absolute_error: 12.5110\n",
      "Epoch 58/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 109735.3791 - mean_absolute_error: 12.4614 - val_loss: 45202.6903 - val_mean_absolute_error: 12.5096\n",
      "Epoch 59/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 91103.4579 - mean_absolute_error: 12.4611 - val_loss: 99327.4864 - val_mean_absolute_error: 12.5113\n",
      "Epoch 60/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 112572.8048 - mean_absolute_error: 12.4613 - val_loss: 93641.7101 - val_mean_absolute_error: 12.5087\n",
      "Epoch 61/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 100301.2533 - mean_absolute_error: 12.4616 - val_loss: 80280.7347 - val_mean_absolute_error: 12.5096\n",
      "Epoch 62/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 101733.9321 - mean_absolute_error: 12.4614 - val_loss: 106532.8207 - val_mean_absolute_error: 12.5091\n",
      "Epoch 63/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 91348.7266 - mean_absolute_error: 12.4615 - val_loss: 93202.5002 - val_mean_absolute_error: 12.5080\n",
      "Epoch 64/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 84773.8281 - mean_absolute_error: 12.4612 - val_loss: 89330.7782 - val_mean_absolute_error: 12.5089\n",
      "Epoch 65/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 105182.3867 - mean_absolute_error: 12.4613 - val_loss: 43641.6463 - val_mean_absolute_error: 12.5091\n",
      "Epoch 66/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 92440.2724 - mean_absolute_error: 12.4613 - val_loss: 99241.1496 - val_mean_absolute_error: 12.5088\n",
      "Epoch 67/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 98191.8794 - mean_absolute_error: 12.4612 - val_loss: 74405.6077 - val_mean_absolute_error: 12.5100\n",
      "Epoch 68/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 97931.4556 - mean_absolute_error: 12.4612 - val_loss: 67700.4087 - val_mean_absolute_error: 12.5099\n",
      "Epoch 69/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 83001.1130 - mean_absolute_error: 12.4614 - val_loss: 60068.4173 - val_mean_absolute_error: 12.5098\n",
      "Epoch 70/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 93910.0556 - mean_absolute_error: 12.4612 - val_loss: 66114.3938 - val_mean_absolute_error: 12.5085\n",
      "Epoch 71/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 110423.2249 - mean_absolute_error: 12.4615 - val_loss: 78695.6884 - val_mean_absolute_error: 12.5097\n",
      "Epoch 72/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 88560.3981 - mean_absolute_error: 12.4612 - val_loss: 95498.9844 - val_mean_absolute_error: 12.5099\n",
      "Epoch 73/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 113731.2423 - mean_absolute_error: 12.4612 - val_loss: 83073.1741 - val_mean_absolute_error: 12.5114\n",
      "Epoch 74/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 109910.0239 - mean_absolute_error: 12.4613 - val_loss: 75873.2884 - val_mean_absolute_error: 12.5084\n",
      "Epoch 75/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 108265.8526 - mean_absolute_error: 12.4612 - val_loss: 159150.7622 - val_mean_absolute_error: 12.5087\n",
      "Epoch 76/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 106482.0718 - mean_absolute_error: 12.4611 - val_loss: 75673.8209 - val_mean_absolute_error: 12.5107\n",
      "Epoch 77/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 80552.2135 - mean_absolute_error: 12.4613 - val_loss: 121334.5565 - val_mean_absolute_error: 12.5107\n",
      "Epoch 78/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 114206.1548 - mean_absolute_error: 12.4614 - val_loss: 58470.9758 - val_mean_absolute_error: 12.5089\n",
      "Epoch 79/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 86573.9163 - mean_absolute_error: 12.4612 - val_loss: 84627.1064 - val_mean_absolute_error: 12.5102\n",
      "Epoch 80/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 81722.1497 - mean_absolute_error: 12.4612 - val_loss: 106034.9787 - val_mean_absolute_error: 12.5107\n",
      "Epoch 81/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 90960.3537 - mean_absolute_error: 12.4612 - val_loss: 99098.5251 - val_mean_absolute_error: 12.5110\n",
      "Epoch 82/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 110819.4315 - mean_absolute_error: 12.4612 - val_loss: 82586.0418 - val_mean_absolute_error: 12.5097\n",
      "Epoch 83/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 85330.0808 - mean_absolute_error: 12.4614 - val_loss: 61650.4486 - val_mean_absolute_error: 12.5098\n",
      "Epoch 84/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 76461.6887 - mean_absolute_error: 12.4612 - val_loss: 82150.1596 - val_mean_absolute_error: 12.5113\n",
      "Epoch 85/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 77056.2414 - mean_absolute_error: 12.4612 - val_loss: 101776.7685 - val_mean_absolute_error: 12.5080\n",
      "Epoch 86/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 81862.9197 - mean_absolute_error: 12.4611 - val_loss: 60308.6787 - val_mean_absolute_error: 12.5101\n",
      "Epoch 87/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 71025.9627 - mean_absolute_error: 12.4612 - val_loss: 73547.8736 - val_mean_absolute_error: 12.5088\n",
      "Epoch 88/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 98044.2192 - mean_absolute_error: 12.4614 - val_loss: 72451.3294 - val_mean_absolute_error: 12.5081\n",
      "Epoch 89/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 80341.4337 - mean_absolute_error: 12.4610 - val_loss: 89743.2604 - val_mean_absolute_error: 12.5106\n",
      "Epoch 90/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 88055.0706 - mean_absolute_error: 12.4614 - val_loss: 110231.9611 - val_mean_absolute_error: 12.5088\n",
      "Epoch 91/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 8us/step - loss: 78550.2136 - mean_absolute_error: 12.4613 - val_loss: 55375.7704 - val_mean_absolute_error: 12.5101\n",
      "Epoch 92/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 85528.0188 - mean_absolute_error: 12.4611 - val_loss: 100235.0483 - val_mean_absolute_error: 12.5098\n",
      "Epoch 93/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 85388.5654 - mean_absolute_error: 12.4609 - val_loss: 101333.2621 - val_mean_absolute_error: 12.5101\n",
      "Epoch 94/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 88079.9630 - mean_absolute_error: 12.4614 - val_loss: 103864.5396 - val_mean_absolute_error: 12.5080\n",
      "Epoch 95/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 82779.7754 - mean_absolute_error: 12.4612 - val_loss: 109584.8906 - val_mean_absolute_error: 12.5095\n",
      "Epoch 96/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 97402.0792 - mean_absolute_error: 12.4610 - val_loss: 69016.4677 - val_mean_absolute_error: 12.5094\n",
      "Epoch 97/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 62325.7392 - mean_absolute_error: 12.4614 - val_loss: 92736.5394 - val_mean_absolute_error: 12.5109\n",
      "Epoch 98/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 100090.8411 - mean_absolute_error: 12.4613 - val_loss: 97502.1071 - val_mean_absolute_error: 12.5108\n",
      "Epoch 99/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 75295.6467 - mean_absolute_error: 12.4615 - val_loss: 89786.5944 - val_mean_absolute_error: 12.5088\n",
      "Epoch 100/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 97649.0410 - mean_absolute_error: 12.4612 - val_loss: 95446.1611 - val_mean_absolute_error: 12.5089\n",
      "Epoch 101/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 97062.4109 - mean_absolute_error: 12.4613 - val_loss: 75316.7207 - val_mean_absolute_error: 12.5091\n",
      "Epoch 102/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 82432.4484 - mean_absolute_error: 12.4613 - val_loss: 103974.8218 - val_mean_absolute_error: 12.5100\n",
      "Epoch 103/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 78866.7057 - mean_absolute_error: 12.4612 - val_loss: 105552.8054 - val_mean_absolute_error: 12.5107\n",
      "Epoch 104/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 93545.9190 - mean_absolute_error: 12.4613 - val_loss: 86640.3640 - val_mean_absolute_error: 12.5097\n",
      "Epoch 105/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 78799.9648 - mean_absolute_error: 12.4612 - val_loss: 62516.9968 - val_mean_absolute_error: 12.5089\n",
      "Epoch 106/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 93458.8846 - mean_absolute_error: 12.4612 - val_loss: 89977.6556 - val_mean_absolute_error: 12.5074\n",
      "Epoch 107/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 83132.8436 - mean_absolute_error: 12.4613 - val_loss: 46708.1846 - val_mean_absolute_error: 12.5094\n",
      "Epoch 108/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 85519.9186 - mean_absolute_error: 12.4611 - val_loss: 63019.4168 - val_mean_absolute_error: 12.5096\n",
      "Epoch 109/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 76620.0309 - mean_absolute_error: 12.4611 - val_loss: 86686.1651 - val_mean_absolute_error: 12.5097\n",
      "Epoch 110/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 91720.0486 - mean_absolute_error: 12.4614 - val_loss: 78373.8546 - val_mean_absolute_error: 12.5086\n",
      "Epoch 111/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 89253.6069 - mean_absolute_error: 12.4612 - val_loss: 102312.9151 - val_mean_absolute_error: 12.5089\n",
      "Epoch 112/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 80213.7419 - mean_absolute_error: 12.4611 - val_loss: 84390.8631 - val_mean_absolute_error: 12.5110\n",
      "Epoch 113/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 100695.2424 - mean_absolute_error: 12.4613 - val_loss: 96899.6006 - val_mean_absolute_error: 12.5089\n",
      "Epoch 114/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 103211.2252 - mean_absolute_error: 12.4612 - val_loss: 106768.6944 - val_mean_absolute_error: 12.5094\n",
      "Epoch 115/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 88429.6566 - mean_absolute_error: 12.4614 - val_loss: 93095.2442 - val_mean_absolute_error: 12.5098\n",
      "Epoch 116/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 79916.1263 - mean_absolute_error: 12.4612 - val_loss: 71294.6149 - val_mean_absolute_error: 12.5089\n",
      "Epoch 117/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 95348.4167 - mean_absolute_error: 12.4612 - val_loss: 67946.4104 - val_mean_absolute_error: 12.5092\n",
      "Epoch 118/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 70127.6100 - mean_absolute_error: 12.4613 - val_loss: 74912.1251 - val_mean_absolute_error: 12.5102\n",
      "Epoch 119/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 85537.1027 - mean_absolute_error: 12.4614 - val_loss: 72777.1382 - val_mean_absolute_error: 12.5098\n",
      "Epoch 120/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 88367.9414 - mean_absolute_error: 12.4612 - val_loss: 99080.5216 - val_mean_absolute_error: 12.5104\n",
      "Epoch 121/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 81434.5699 - mean_absolute_error: 12.4613 - val_loss: 66987.2134 - val_mean_absolute_error: 12.5113\n",
      "Epoch 122/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 79173.8261 - mean_absolute_error: 12.4612 - val_loss: 85632.6366 - val_mean_absolute_error: 12.5106\n",
      "Epoch 123/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 106785.3594 - mean_absolute_error: 12.4612 - val_loss: 73524.2740 - val_mean_absolute_error: 12.5089\n",
      "Epoch 124/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 78276.5577 - mean_absolute_error: 12.4610 - val_loss: 63363.2917 - val_mean_absolute_error: 12.5106\n",
      "Epoch 125/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 78947.0166 - mean_absolute_error: 12.4613 - val_loss: 48011.9053 - val_mean_absolute_error: 12.5106\n",
      "Epoch 126/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 88240.0734 - mean_absolute_error: 12.4614 - val_loss: 55396.1277 - val_mean_absolute_error: 12.5095\n",
      "Epoch 127/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 81251.6438 - mean_absolute_error: 12.4611 - val_loss: 72516.1582 - val_mean_absolute_error: 12.5093\n",
      "Epoch 128/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 88378.8739 - mean_absolute_error: 12.4611 - val_loss: 92122.8291 - val_mean_absolute_error: 12.5097\n",
      "Epoch 129/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 90777.8770 - mean_absolute_error: 12.4612 - val_loss: 59783.4408 - val_mean_absolute_error: 12.5094\n",
      "Epoch 130/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 76651.4473 - mean_absolute_error: 12.4614 - val_loss: 105614.6399 - val_mean_absolute_error: 12.5118\n",
      "Epoch 131/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 79199.3293 - mean_absolute_error: 12.4613 - val_loss: 97304.7046 - val_mean_absolute_error: 12.5096\n",
      "Epoch 132/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 75407.7067 - mean_absolute_error: 12.4613 - val_loss: 69842.8712 - val_mean_absolute_error: 12.5093\n",
      "Epoch 133/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 97403.1522 - mean_absolute_error: 12.4615 - val_loss: 105443.6916 - val_mean_absolute_error: 12.5096\n",
      "Epoch 134/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 80975.4542 - mean_absolute_error: 12.4613 - val_loss: 61879.4997 - val_mean_absolute_error: 12.5087\n",
      "Epoch 135/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 95109.5357 - mean_absolute_error: 12.4613 - val_loss: 111761.8302 - val_mean_absolute_error: 12.5109\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 8us/step - loss: 81282.6777 - mean_absolute_error: 12.4612 - val_loss: 64311.4920 - val_mean_absolute_error: 12.5100\n",
      "Epoch 137/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 70476.2775 - mean_absolute_error: 12.4614 - val_loss: 102498.3884 - val_mean_absolute_error: 12.5096\n",
      "Epoch 138/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 81461.3403 - mean_absolute_error: 12.4612 - val_loss: 85192.0606 - val_mean_absolute_error: 12.5106\n",
      "Epoch 139/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 81932.5014 - mean_absolute_error: 12.4612 - val_loss: 124481.3831 - val_mean_absolute_error: 12.5104\n",
      "Epoch 140/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 91182.1652 - mean_absolute_error: 12.4615 - val_loss: 100754.6376 - val_mean_absolute_error: 12.5096\n",
      "Epoch 141/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 85861.5908 - mean_absolute_error: 12.4613 - val_loss: 56772.2500 - val_mean_absolute_error: 12.5091\n",
      "Epoch 142/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 74598.9239 - mean_absolute_error: 12.4615 - val_loss: 90255.4907 - val_mean_absolute_error: 12.5105\n",
      "Epoch 143/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 90756.0252 - mean_absolute_error: 12.4610 - val_loss: 93234.1107 - val_mean_absolute_error: 12.5101\n",
      "Epoch 144/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 70664.2816 - mean_absolute_error: 12.4612 - val_loss: 52563.5033 - val_mean_absolute_error: 12.5098\n",
      "Epoch 145/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 78430.5292 - mean_absolute_error: 12.4614 - val_loss: 97988.6633 - val_mean_absolute_error: 12.5084\n",
      "Epoch 146/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 87906.3878 - mean_absolute_error: 12.4611 - val_loss: 50745.7501 - val_mean_absolute_error: 12.5093\n",
      "Epoch 147/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 87096.5185 - mean_absolute_error: 12.4613 - val_loss: 66240.4014 - val_mean_absolute_error: 12.5103\n",
      "Epoch 148/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 75300.4044 - mean_absolute_error: 12.4612 - val_loss: 49738.7335 - val_mean_absolute_error: 12.5091\n",
      "Epoch 149/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 64092.6467 - mean_absolute_error: 12.4613 - val_loss: 123658.4609 - val_mean_absolute_error: 12.5113\n",
      "Epoch 150/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 88070.7225 - mean_absolute_error: 12.4614 - val_loss: 86713.9651 - val_mean_absolute_error: 12.5093\n",
      "Epoch 151/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 75468.2766 - mean_absolute_error: 12.4613 - val_loss: 64175.0481 - val_mean_absolute_error: 12.5098\n",
      "Epoch 152/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 89982.1206 - mean_absolute_error: 12.4613 - val_loss: 75158.1962 - val_mean_absolute_error: 12.5096\n",
      "Epoch 153/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 76512.3477 - mean_absolute_error: 12.4611 - val_loss: 86184.8412 - val_mean_absolute_error: 12.5107\n",
      "Epoch 154/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 70810.2082 - mean_absolute_error: 12.4614 - val_loss: 59753.4199 - val_mean_absolute_error: 12.5090\n",
      "Epoch 155/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 75932.4750 - mean_absolute_error: 12.4614 - val_loss: 87111.4126 - val_mean_absolute_error: 12.5088\n",
      "Epoch 156/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 76469.6535 - mean_absolute_error: 12.4612 - val_loss: 55490.5025 - val_mean_absolute_error: 12.5089\n",
      "Epoch 157/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 63831.7710 - mean_absolute_error: 12.4612 - val_loss: 74583.5750 - val_mean_absolute_error: 12.5096\n",
      "Epoch 158/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 89158.5473 - mean_absolute_error: 12.4612 - val_loss: 104253.7146 - val_mean_absolute_error: 12.5110\n",
      "Epoch 159/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 82945.2243 - mean_absolute_error: 12.4612 - val_loss: 113523.8051 - val_mean_absolute_error: 12.5092\n",
      "Epoch 160/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 71084.9070 - mean_absolute_error: 12.4614 - val_loss: 95185.9594 - val_mean_absolute_error: 12.5115\n",
      "Epoch 161/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 80709.9828 - mean_absolute_error: 12.4613 - val_loss: 98890.7691 - val_mean_absolute_error: 12.5104\n",
      "Epoch 162/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 82955.8751 - mean_absolute_error: 12.4614 - val_loss: 102740.3421 - val_mean_absolute_error: 12.5108\n",
      "Epoch 163/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 95695.8345 - mean_absolute_error: 12.4612 - val_loss: 88877.2565 - val_mean_absolute_error: 12.5105\n",
      "Epoch 164/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 80902.9751 - mean_absolute_error: 12.4614 - val_loss: 94991.9674 - val_mean_absolute_error: 12.5106\n",
      "Epoch 165/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 86841.3349 - mean_absolute_error: 12.4613 - val_loss: 66770.4819 - val_mean_absolute_error: 12.5101\n",
      "Epoch 166/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 80250.6674 - mean_absolute_error: 12.4614 - val_loss: 70040.9542 - val_mean_absolute_error: 12.5100\n",
      "Epoch 167/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 76245.3155 - mean_absolute_error: 12.4613 - val_loss: 76612.5519 - val_mean_absolute_error: 12.5090\n",
      "Epoch 168/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 65501.8427 - mean_absolute_error: 12.4614 - val_loss: 83520.2070 - val_mean_absolute_error: 12.5090\n",
      "Epoch 169/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 82719.4567 - mean_absolute_error: 12.4612 - val_loss: 92266.8419 - val_mean_absolute_error: 12.5093\n",
      "Epoch 170/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 59720.8364 - mean_absolute_error: 12.4612 - val_loss: 58888.6806 - val_mean_absolute_error: 12.5095\n",
      "Epoch 171/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 72929.1537 - mean_absolute_error: 12.4613 - val_loss: 47547.5749 - val_mean_absolute_error: 12.5094\n",
      "Epoch 172/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 62254.6508 - mean_absolute_error: 12.4614 - val_loss: 86720.0276 - val_mean_absolute_error: 12.5094\n",
      "Epoch 173/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 94193.3433 - mean_absolute_error: 12.4612 - val_loss: 32921.5936 - val_mean_absolute_error: 12.5098\n",
      "Epoch 174/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 66379.9702 - mean_absolute_error: 12.4613 - val_loss: 73580.3668 - val_mean_absolute_error: 12.5093\n",
      "Epoch 175/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 63753.9021 - mean_absolute_error: 12.4613 - val_loss: 59287.6167 - val_mean_absolute_error: 12.5098\n",
      "Epoch 176/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 73121.9624 - mean_absolute_error: 12.4613 - val_loss: 71346.9357 - val_mean_absolute_error: 12.5092\n",
      "Epoch 177/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 66253.0971 - mean_absolute_error: 12.4611 - val_loss: 77191.0948 - val_mean_absolute_error: 12.5100\n",
      "Epoch 178/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55786.5379 - mean_absolute_error: 12.4613 - val_loss: 60738.0049 - val_mean_absolute_error: 12.5091\n",
      "Epoch 179/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 65241.0237 - mean_absolute_error: 12.4612 - val_loss: 63672.3813 - val_mean_absolute_error: 12.5091\n",
      "Epoch 180/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 63051.1826 - mean_absolute_error: 12.4612 - val_loss: 39984.8347 - val_mean_absolute_error: 12.5099\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 8us/step - loss: 65140.6961 - mean_absolute_error: 12.4614 - val_loss: 72532.8010 - val_mean_absolute_error: 12.5101\n",
      "Epoch 182/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 78135.3597 - mean_absolute_error: 12.4612 - val_loss: 65110.3508 - val_mean_absolute_error: 12.5091\n",
      "Epoch 183/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 57667.3222 - mean_absolute_error: 12.4612 - val_loss: 63615.9587 - val_mean_absolute_error: 12.5106\n",
      "Epoch 184/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 68829.1956 - mean_absolute_error: 12.4614 - val_loss: 54102.4522 - val_mean_absolute_error: 12.5089\n",
      "Epoch 185/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 59496.7078 - mean_absolute_error: 12.4612 - val_loss: 56095.5340 - val_mean_absolute_error: 12.5100\n",
      "Epoch 186/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 78561.9148 - mean_absolute_error: 12.4613 - val_loss: 111371.0484 - val_mean_absolute_error: 12.5096\n",
      "Epoch 187/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 82424.5086 - mean_absolute_error: 12.4613 - val_loss: 84965.3666 - val_mean_absolute_error: 12.5091\n",
      "Epoch 188/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 65633.4517 - mean_absolute_error: 12.4613 - val_loss: 40808.1701 - val_mean_absolute_error: 12.5096\n",
      "Epoch 189/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 57335.6297 - mean_absolute_error: 12.4612 - val_loss: 42691.8499 - val_mean_absolute_error: 12.5089\n",
      "Epoch 190/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 64105.7035 - mean_absolute_error: 12.4612 - val_loss: 109334.5779 - val_mean_absolute_error: 12.5111\n",
      "Epoch 191/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 84272.8381 - mean_absolute_error: 12.4614 - val_loss: 54386.1962 - val_mean_absolute_error: 12.5094\n",
      "Epoch 192/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 67593.4649 - mean_absolute_error: 12.4612 - val_loss: 64671.8177 - val_mean_absolute_error: 12.5087\n",
      "Epoch 193/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 76859.3820 - mean_absolute_error: 12.4611 - val_loss: 70668.5900 - val_mean_absolute_error: 12.5097\n",
      "Epoch 194/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 85866.2325 - mean_absolute_error: 12.4609 - val_loss: 59785.6729 - val_mean_absolute_error: 12.5095\n",
      "Epoch 195/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 78652.1760 - mean_absolute_error: 12.4615 - val_loss: 58382.0589 - val_mean_absolute_error: 12.5102\n",
      "Epoch 196/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 63751.2507 - mean_absolute_error: 12.4612 - val_loss: 62994.5812 - val_mean_absolute_error: 12.5094\n",
      "Epoch 197/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 67343.1828 - mean_absolute_error: 12.4612 - val_loss: 46295.4436 - val_mean_absolute_error: 12.5095\n",
      "Epoch 198/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 71197.1071 - mean_absolute_error: 12.4614 - val_loss: 61271.0717 - val_mean_absolute_error: 12.5105\n",
      "Epoch 199/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 61007.2616 - mean_absolute_error: 12.4612 - val_loss: 58369.8019 - val_mean_absolute_error: 12.5090\n",
      "Epoch 200/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 80428.8828 - mean_absolute_error: 12.4613 - val_loss: 58876.5214 - val_mean_absolute_error: 12.5091\n",
      "Epoch 201/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 68080.5961 - mean_absolute_error: 12.4612 - val_loss: 76207.8069 - val_mean_absolute_error: 12.5093\n",
      "Epoch 202/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 66956.6513 - mean_absolute_error: 12.4612 - val_loss: 68706.3731 - val_mean_absolute_error: 12.5105\n",
      "Epoch 203/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 73618.7856 - mean_absolute_error: 12.4613 - val_loss: 59583.0661 - val_mean_absolute_error: 12.5090\n",
      "Epoch 204/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 61828.6256 - mean_absolute_error: 12.4611 - val_loss: 83191.7459 - val_mean_absolute_error: 12.5095\n",
      "Epoch 205/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 69870.0574 - mean_absolute_error: 12.4612 - val_loss: 94575.4096 - val_mean_absolute_error: 12.5102\n",
      "Epoch 206/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 73389.1999 - mean_absolute_error: 12.4614 - val_loss: 36958.7825 - val_mean_absolute_error: 12.5092\n",
      "Epoch 207/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 71878.2137 - mean_absolute_error: 12.4612 - val_loss: 110546.4526 - val_mean_absolute_error: 12.5105\n",
      "Epoch 208/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 66047.0729 - mean_absolute_error: 12.4612 - val_loss: 30299.1238 - val_mean_absolute_error: 12.5100\n",
      "Epoch 209/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 57525.5647 - mean_absolute_error: 12.4612 - val_loss: 76978.7401 - val_mean_absolute_error: 12.5093\n",
      "Epoch 210/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 60775.6669 - mean_absolute_error: 12.4613 - val_loss: 45115.7343 - val_mean_absolute_error: 12.5101\n",
      "Epoch 211/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 69711.1333 - mean_absolute_error: 12.4612 - val_loss: 76707.1015 - val_mean_absolute_error: 12.5098\n",
      "Epoch 212/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 69746.7307 - mean_absolute_error: 12.4614 - val_loss: 68100.0046 - val_mean_absolute_error: 12.5090\n",
      "Epoch 213/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 65428.4976 - mean_absolute_error: 12.4613 - val_loss: 74996.7002 - val_mean_absolute_error: 12.5111\n",
      "Epoch 214/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 50487.0805 - mean_absolute_error: 12.4613 - val_loss: 53781.9515 - val_mean_absolute_error: 12.5092\n",
      "Epoch 215/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 58350.8610 - mean_absolute_error: 12.4612 - val_loss: 55080.0112 - val_mean_absolute_error: 12.5101\n",
      "Epoch 216/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55211.4733 - mean_absolute_error: 12.4612 - val_loss: 31617.8242 - val_mean_absolute_error: 12.5093\n",
      "Epoch 217/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 52626.7007 - mean_absolute_error: 12.4613 - val_loss: 48540.3384 - val_mean_absolute_error: 12.5098\n",
      "Epoch 218/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 63030.4309 - mean_absolute_error: 12.4611 - val_loss: 44576.9734 - val_mean_absolute_error: 12.5102\n",
      "Epoch 219/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 64977.8854 - mean_absolute_error: 12.4612 - val_loss: 61270.1505 - val_mean_absolute_error: 12.5100\n",
      "Epoch 220/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 56739.1598 - mean_absolute_error: 12.4612 - val_loss: 50502.5359 - val_mean_absolute_error: 12.5096\n",
      "Epoch 221/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 51956.2064 - mean_absolute_error: 12.4612 - val_loss: 81966.7983 - val_mean_absolute_error: 12.5083\n",
      "Epoch 222/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 62071.6264 - mean_absolute_error: 12.4614 - val_loss: 55978.4975 - val_mean_absolute_error: 12.5100\n",
      "Epoch 223/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 51900.3264 - mean_absolute_error: 12.4613 - val_loss: 35129.8395 - val_mean_absolute_error: 12.5101\n",
      "Epoch 224/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 55521.7214 - mean_absolute_error: 12.4613 - val_loss: 49769.6946 - val_mean_absolute_error: 12.5102\n",
      "Epoch 225/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 56891.0352 - mean_absolute_error: 12.4613 - val_loss: 75294.5071 - val_mean_absolute_error: 12.5090\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 8us/step - loss: 74605.9303 - mean_absolute_error: 12.4611 - val_loss: 84204.6314 - val_mean_absolute_error: 12.5098\n",
      "Epoch 227/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 69878.3515 - mean_absolute_error: 12.4613 - val_loss: 52580.1848 - val_mean_absolute_error: 12.5092\n",
      "Epoch 228/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 65572.3827 - mean_absolute_error: 12.4613 - val_loss: 50727.8327 - val_mean_absolute_error: 12.5096\n",
      "Epoch 229/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 65508.5510 - mean_absolute_error: 12.4613 - val_loss: 49602.1675 - val_mean_absolute_error: 12.5094\n",
      "Epoch 230/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 72389.2135 - mean_absolute_error: 12.4613 - val_loss: 89712.8294 - val_mean_absolute_error: 12.5088\n",
      "Epoch 231/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 68105.1726 - mean_absolute_error: 12.4614 - val_loss: 65097.3252 - val_mean_absolute_error: 12.5101\n",
      "Epoch 232/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 51415.4984 - mean_absolute_error: 12.4613 - val_loss: 74179.0699 - val_mean_absolute_error: 12.5094\n",
      "Epoch 233/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 63309.5926 - mean_absolute_error: 12.4612 - val_loss: 76419.4581 - val_mean_absolute_error: 12.5101\n",
      "Epoch 234/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 67866.0828 - mean_absolute_error: 12.4613 - val_loss: 66565.3833 - val_mean_absolute_error: 12.5102\n",
      "Epoch 235/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55870.7707 - mean_absolute_error: 12.4612 - val_loss: 45217.6112 - val_mean_absolute_error: 12.5105\n",
      "Epoch 236/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 69628.3389 - mean_absolute_error: 12.4614 - val_loss: 70934.2654 - val_mean_absolute_error: 12.5099\n",
      "Epoch 237/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 51401.7459 - mean_absolute_error: 12.4612 - val_loss: 62901.1347 - val_mean_absolute_error: 12.5104\n",
      "Epoch 238/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 66564.8947 - mean_absolute_error: 12.4613 - val_loss: 52162.6481 - val_mean_absolute_error: 12.5097\n",
      "Epoch 239/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 59331.1966 - mean_absolute_error: 12.4613 - val_loss: 59892.1367 - val_mean_absolute_error: 12.5090\n",
      "Epoch 240/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 72939.8743 - mean_absolute_error: 12.4612 - val_loss: 76764.0047 - val_mean_absolute_error: 12.5089\n",
      "Epoch 241/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 54967.0060 - mean_absolute_error: 12.4612 - val_loss: 55374.1783 - val_mean_absolute_error: 12.5096\n",
      "Epoch 242/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 50957.0146 - mean_absolute_error: 12.4613 - val_loss: 40520.6819 - val_mean_absolute_error: 12.5098\n",
      "Epoch 243/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 67035.9101 - mean_absolute_error: 12.4612 - val_loss: 46232.2136 - val_mean_absolute_error: 12.5092\n",
      "Epoch 244/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 58655.9449 - mean_absolute_error: 12.4612 - val_loss: 46295.4447 - val_mean_absolute_error: 12.5093\n",
      "Epoch 245/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 66931.2023 - mean_absolute_error: 12.4614 - val_loss: 39058.6525 - val_mean_absolute_error: 12.5093\n",
      "Epoch 246/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55466.2686 - mean_absolute_error: 12.4611 - val_loss: 72642.7743 - val_mean_absolute_error: 12.5100\n",
      "Epoch 247/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 70977.6389 - mean_absolute_error: 12.4613 - val_loss: 43910.3830 - val_mean_absolute_error: 12.5087\n",
      "Epoch 248/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 60388.2948 - mean_absolute_error: 12.4611 - val_loss: 79105.9353 - val_mean_absolute_error: 12.5109\n",
      "Epoch 249/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 50090.7087 - mean_absolute_error: 12.4613 - val_loss: 65770.0027 - val_mean_absolute_error: 12.5094\n",
      "Epoch 250/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 48773.5578 - mean_absolute_error: 12.4613 - val_loss: 31117.5046 - val_mean_absolute_error: 12.5101\n",
      "Epoch 251/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 50289.7817 - mean_absolute_error: 12.4612 - val_loss: 52088.6617 - val_mean_absolute_error: 12.5097\n",
      "Epoch 252/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 48378.1829 - mean_absolute_error: 12.4613 - val_loss: 45346.9012 - val_mean_absolute_error: 12.5092\n",
      "Epoch 253/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 59297.6249 - mean_absolute_error: 12.4613 - val_loss: 76498.4032 - val_mean_absolute_error: 12.5095\n",
      "Epoch 254/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 47596.4139 - mean_absolute_error: 12.4612 - val_loss: 52972.6693 - val_mean_absolute_error: 12.5093\n",
      "Epoch 255/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 56486.8037 - mean_absolute_error: 12.4612 - val_loss: 39925.2890 - val_mean_absolute_error: 12.5102\n",
      "Epoch 256/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 45239.3563 - mean_absolute_error: 12.4613 - val_loss: 58450.7894 - val_mean_absolute_error: 12.5094\n",
      "Epoch 257/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 65739.2368 - mean_absolute_error: 12.4612 - val_loss: 60326.4895 - val_mean_absolute_error: 12.5093\n",
      "Epoch 258/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55611.1438 - mean_absolute_error: 12.4610 - val_loss: 96520.0751 - val_mean_absolute_error: 12.5080\n",
      "Epoch 259/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 56154.7599 - mean_absolute_error: 12.4611 - val_loss: 62880.3527 - val_mean_absolute_error: 12.5094\n",
      "Epoch 260/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 68772.2619 - mean_absolute_error: 12.4612 - val_loss: 55845.9769 - val_mean_absolute_error: 12.5111\n",
      "Epoch 261/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 44336.3814 - mean_absolute_error: 12.4613 - val_loss: 63591.9616 - val_mean_absolute_error: 12.5100\n",
      "Epoch 262/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 41917.5854 - mean_absolute_error: 12.4612 - val_loss: 32665.2925 - val_mean_absolute_error: 12.5095\n",
      "Epoch 263/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 46730.9310 - mean_absolute_error: 12.4613 - val_loss: 42970.4404 - val_mean_absolute_error: 12.5104\n",
      "Epoch 264/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 56043.0246 - mean_absolute_error: 12.4612 - val_loss: 58148.4178 - val_mean_absolute_error: 12.5103\n",
      "Epoch 265/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 49658.3638 - mean_absolute_error: 12.4613 - val_loss: 71726.3411 - val_mean_absolute_error: 12.5083\n",
      "Epoch 266/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 62266.2943 - mean_absolute_error: 12.4612 - val_loss: 69740.4793 - val_mean_absolute_error: 12.5092\n",
      "Epoch 267/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 53399.1483 - mean_absolute_error: 12.4614 - val_loss: 53927.1189 - val_mean_absolute_error: 12.5095\n",
      "Epoch 268/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 50977.8987 - mean_absolute_error: 12.4613 - val_loss: 45764.9176 - val_mean_absolute_error: 12.5104\n",
      "Epoch 269/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 63272.0980 - mean_absolute_error: 12.4615 - val_loss: 78066.2476 - val_mean_absolute_error: 12.5109\n",
      "Epoch 270/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55829.9033 - mean_absolute_error: 12.4613 - val_loss: 46941.8247 - val_mean_absolute_error: 12.5097\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 8us/step - loss: 46054.3418 - mean_absolute_error: 12.4612 - val_loss: 30667.9429 - val_mean_absolute_error: 12.5100\n",
      "Epoch 272/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55899.3528 - mean_absolute_error: 12.4612 - val_loss: 81641.0398 - val_mean_absolute_error: 12.5098\n",
      "Epoch 273/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 63963.3348 - mean_absolute_error: 12.4612 - val_loss: 54366.6303 - val_mean_absolute_error: 12.5089\n",
      "Epoch 274/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 51896.9424 - mean_absolute_error: 12.4612 - val_loss: 43179.6974 - val_mean_absolute_error: 12.5103\n",
      "Epoch 275/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 57420.6674 - mean_absolute_error: 12.4613 - val_loss: 54598.0049 - val_mean_absolute_error: 12.5096\n",
      "Epoch 276/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 60684.9868 - mean_absolute_error: 12.4613 - val_loss: 77261.7555 - val_mean_absolute_error: 12.5102\n",
      "Epoch 277/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 56671.0560 - mean_absolute_error: 12.4612 - val_loss: 31106.5972 - val_mean_absolute_error: 12.5097\n",
      "Epoch 278/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 41341.8284 - mean_absolute_error: 12.4612 - val_loss: 42976.9035 - val_mean_absolute_error: 12.5092\n",
      "Epoch 279/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 61850.4145 - mean_absolute_error: 12.4613 - val_loss: 53478.8757 - val_mean_absolute_error: 12.5095\n",
      "Epoch 280/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 45254.5643 - mean_absolute_error: 12.4612 - val_loss: 45429.8004 - val_mean_absolute_error: 12.5091\n",
      "Epoch 281/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 67667.2144 - mean_absolute_error: 12.4612 - val_loss: 86485.2626 - val_mean_absolute_error: 12.5100\n",
      "Epoch 282/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 56392.9645 - mean_absolute_error: 12.4613 - val_loss: 49029.5523 - val_mean_absolute_error: 12.5091\n",
      "Epoch 283/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 49924.9448 - mean_absolute_error: 12.4613 - val_loss: 49844.8098 - val_mean_absolute_error: 12.5093\n",
      "Epoch 284/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 57123.0643 - mean_absolute_error: 12.4612 - val_loss: 39203.5886 - val_mean_absolute_error: 12.5095\n",
      "Epoch 285/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 48642.7996 - mean_absolute_error: 12.4611 - val_loss: 50040.3932 - val_mean_absolute_error: 12.5100\n",
      "Epoch 286/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 60311.9248 - mean_absolute_error: 12.4612 - val_loss: 49028.9515 - val_mean_absolute_error: 12.5102\n",
      "Epoch 287/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55228.2674 - mean_absolute_error: 12.4612 - val_loss: 63686.7161 - val_mean_absolute_error: 12.5095\n",
      "Epoch 288/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 64724.0745 - mean_absolute_error: 12.4613 - val_loss: 65980.5818 - val_mean_absolute_error: 12.5102\n",
      "Epoch 289/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 60295.8872 - mean_absolute_error: 12.4612 - val_loss: 25870.7558 - val_mean_absolute_error: 12.5095\n",
      "Epoch 290/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 42057.7048 - mean_absolute_error: 12.4613 - val_loss: 46444.4120 - val_mean_absolute_error: 12.5086\n",
      "Epoch 291/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 52065.5962 - mean_absolute_error: 12.4612 - val_loss: 45640.8514 - val_mean_absolute_error: 12.5085\n",
      "Epoch 292/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 37547.5156 - mean_absolute_error: 12.4612 - val_loss: 43759.2125 - val_mean_absolute_error: 12.5099\n",
      "Epoch 293/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 46509.2738 - mean_absolute_error: 12.4613 - val_loss: 48008.9472 - val_mean_absolute_error: 12.5098\n",
      "Epoch 294/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55514.8220 - mean_absolute_error: 12.4613 - val_loss: 43679.6366 - val_mean_absolute_error: 12.5091\n",
      "Epoch 295/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55245.1639 - mean_absolute_error: 12.4612 - val_loss: 48277.5999 - val_mean_absolute_error: 12.5098\n",
      "Epoch 296/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 49405.0880 - mean_absolute_error: 12.4612 - val_loss: 39370.2744 - val_mean_absolute_error: 12.5097\n",
      "Epoch 297/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 44011.6718 - mean_absolute_error: 12.4614 - val_loss: 43006.7395 - val_mean_absolute_error: 12.5095\n",
      "Epoch 298/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 57066.3551 - mean_absolute_error: 12.4611 - val_loss: 40666.1472 - val_mean_absolute_error: 12.5093\n",
      "Epoch 299/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 49165.8543 - mean_absolute_error: 12.4612 - val_loss: 54325.1648 - val_mean_absolute_error: 12.5091\n",
      "Epoch 300/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 53133.9461 - mean_absolute_error: 12.4612 - val_loss: 25366.7656 - val_mean_absolute_error: 12.5097\n",
      "Epoch 301/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 51065.2988 - mean_absolute_error: 12.4612 - val_loss: 50471.5885 - val_mean_absolute_error: 12.5090\n",
      "Epoch 302/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 56991.0771 - mean_absolute_error: 12.4613 - val_loss: 24547.0280 - val_mean_absolute_error: 12.5094\n",
      "Epoch 303/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 43666.0159 - mean_absolute_error: 12.4612 - val_loss: 34520.0396 - val_mean_absolute_error: 12.5100\n",
      "Epoch 304/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 52197.4247 - mean_absolute_error: 12.4612 - val_loss: 32339.4925 - val_mean_absolute_error: 12.5092\n",
      "Epoch 305/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 40906.8413 - mean_absolute_error: 12.4611 - val_loss: 46337.0729 - val_mean_absolute_error: 12.5099\n",
      "Epoch 306/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 48704.9814 - mean_absolute_error: 12.4612 - val_loss: 58167.7023 - val_mean_absolute_error: 12.5100\n",
      "Epoch 307/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 52804.6733 - mean_absolute_error: 12.4613 - val_loss: 40629.9426 - val_mean_absolute_error: 12.5104\n",
      "Epoch 308/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 61910.7002 - mean_absolute_error: 12.4613 - val_loss: 48419.0433 - val_mean_absolute_error: 12.5096\n",
      "Epoch 309/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 52027.9234 - mean_absolute_error: 12.4611 - val_loss: 66895.9350 - val_mean_absolute_error: 12.5098\n",
      "Epoch 310/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 47317.4129 - mean_absolute_error: 12.4614 - val_loss: 44331.3478 - val_mean_absolute_error: 12.5094\n",
      "Epoch 311/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 49464.0186 - mean_absolute_error: 12.4612 - val_loss: 45548.9918 - val_mean_absolute_error: 12.5094\n",
      "Epoch 312/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 42798.1827 - mean_absolute_error: 12.4612 - val_loss: 24112.0483 - val_mean_absolute_error: 12.5095\n",
      "Epoch 313/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 41267.6026 - mean_absolute_error: 12.4612 - val_loss: 46330.3152 - val_mean_absolute_error: 12.5098\n",
      "Epoch 314/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 53316.7378 - mean_absolute_error: 12.4612 - val_loss: 45609.6142 - val_mean_absolute_error: 12.5096\n",
      "Epoch 315/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 45495.5323 - mean_absolute_error: 12.4613 - val_loss: 43327.0699 - val_mean_absolute_error: 12.5097\n",
      "Epoch 316/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 8us/step - loss: 43997.4381 - mean_absolute_error: 12.4613 - val_loss: 47028.6328 - val_mean_absolute_error: 12.5096\n",
      "Epoch 317/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 51742.4510 - mean_absolute_error: 12.4613 - val_loss: 53489.1200 - val_mean_absolute_error: 12.5090\n",
      "Epoch 318/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 46203.5903 - mean_absolute_error: 12.4612 - val_loss: 37940.1878 - val_mean_absolute_error: 12.5099\n",
      "Epoch 319/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 47978.5497 - mean_absolute_error: 12.4612 - val_loss: 34136.5042 - val_mean_absolute_error: 12.5104\n",
      "Epoch 320/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 51092.2458 - mean_absolute_error: 12.4612 - val_loss: 43756.4195 - val_mean_absolute_error: 12.5102\n",
      "Epoch 321/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 51395.2757 - mean_absolute_error: 12.4613 - val_loss: 80806.4857 - val_mean_absolute_error: 12.5105\n",
      "Epoch 322/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 43085.3753 - mean_absolute_error: 12.4613 - val_loss: 38717.3719 - val_mean_absolute_error: 12.5091\n",
      "Epoch 323/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 48013.9834 - mean_absolute_error: 12.4612 - val_loss: 50675.4419 - val_mean_absolute_error: 12.5091\n",
      "Epoch 324/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 42315.7005 - mean_absolute_error: 12.4613 - val_loss: 65572.7594 - val_mean_absolute_error: 12.5105\n",
      "Epoch 325/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 55366.1419 - mean_absolute_error: 12.4613 - val_loss: 53472.7415 - val_mean_absolute_error: 12.5097\n",
      "Epoch 326/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 48986.8805 - mean_absolute_error: 12.4613 - val_loss: 58379.0272 - val_mean_absolute_error: 12.5089\n",
      "Epoch 327/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 47008.0135 - mean_absolute_error: 12.4614 - val_loss: 41009.1647 - val_mean_absolute_error: 12.5094\n",
      "Epoch 328/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 47293.7123 - mean_absolute_error: 12.4612 - val_loss: 35179.8687 - val_mean_absolute_error: 12.5089\n",
      "Epoch 329/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 47089.5467 - mean_absolute_error: 12.4611 - val_loss: 36309.9371 - val_mean_absolute_error: 12.5092\n",
      "Epoch 330/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 42943.8458 - mean_absolute_error: 12.4612 - val_loss: 53138.9408 - val_mean_absolute_error: 12.5102\n",
      "Epoch 331/1000\n",
      " 128/8000 [..............................] - ETA: 0s - loss: 60864.2305 - mean_absolute_error: 12.5443"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-b43edb9282ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtraining_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtraining_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[0;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   4117\u001b[0m     \"\"\"\n\u001b[0;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 4119\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   4120\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4033\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4034\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   4150\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4152\u001b[1;33m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Actual generation of training_data\n",
    "training_data = generate_training_data()\n",
    "training_inputs = training_data[0]\n",
    "training_outputs = training_data[1]\n",
    "history = model.fit(training_inputs,training_outputs,batch_size=128,epochs=1000,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "test_data = generate_training_data(100)\n",
    "test_inputs = test_data[0]\n",
    "test_outputs = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAA SRMFEIOZLK\n",
      "AAAAAAAAAA TAVIAIXMDU\n",
      "AAAAAAAAAA MZTURNNXUZ\n",
      "AAAAAAAAAA WMWZQGAFIU\n",
      "AAAAAAAAAA UTTLBTQAGW\n",
      "AAAAAAAAAA YATZKVNKMU\n",
      "AAAAAAAAAA ZDCVENHCNT\n",
      "AAAAAAAAAA QFDWREENXX\n",
      "AAAAAAAAAA QYTBBVFFTI\n",
      "AAAAAAAAAA KBFAWWNKGZ\n",
      "AAAAAAAAAA QQLTVYKDKB\n",
      "AAAAAAAAAA OXHHCZIIQY\n",
      "AAAAAAAAAA ARNMMBQKMS\n",
      "AAAAAAAAAA DSRXHPZMQW\n",
      "AAAAAAAAAA CJYXNZKHJB\n",
      "AAAAAAAAAA SMWFDKLEUY\n",
      "AAAAAAAAAA JMZDGESEJN\n",
      "AAAAAAAAAA WNIRFLVYJK\n",
      "AAAAAAAAAA VNWCNTWRRX\n",
      "AAAAAAAAAA AOBXHJTGPA\n",
      "AAAAAAAAAA HZFOUGVNLB\n",
      "AAAAAAAAAA WPBRBCIXOA\n",
      "AAAAAAAAAA MYSVKVWQFI\n",
      "AAAAAAAAAA EONEEOMLGH\n",
      "AAAAAAAAAA LDNGNGMZEL\n",
      "AAAAAAAAAA IWCOBCHTKD\n",
      "AAAAAAAAAA LVZVPBYRWK\n",
      "AAAAAAAAAA ZGTGCTOLGS\n",
      "AAAAAAAAAA WSSVNJRNRO\n",
      "AAAAAAAAAA OABENXRKEB\n",
      "AAAAAAAAAA VLHVJYOQSU\n",
      "AAAAAAAAAA MKHPAZSJGK\n",
      "AAAAAAAAAA HZZJEDERAO\n",
      "AAAAAAAAAA MLTOGYEGXM\n",
      "AAAAAAAAAA DJDKNVJKZP\n",
      "AAAAAAAAAA CHCKQSYAPQ\n",
      "AAAAAAAAAA KZZULGCXBQ\n",
      "AAAAAAAAAA RKZIDYBLQS\n",
      "AAAAAAAAAA PETZBNZHLB\n",
      "AAAAAAAAAA EVNODMZVNV\n",
      "AAAAAAAAAA PQNEDNGOAB\n",
      "AAAAAAAAAA LJQKLCMCNR\n",
      "AAAAAAAAAA ZGIUSWHIGB\n",
      "AAAAAAAAAA CNWBLSCJYU\n",
      "AAAAAAAAAA KSIKSHOTEG\n",
      "AAAAAAAAAA TDACUKKNMV\n",
      "AAAAAAAAAA XBOOFCCKCY\n",
      "AAAAAAAAAA XOKFZCSNXK\n",
      "AAAAAAAAAA QLSAIJEMWN\n",
      "AAAAAAAAAA YFBMZWVMYO\n",
      "AAAAAAAAAA VGRORINVXL\n",
      "AAAAAAAAAA EVCVHSBJOD\n",
      "AAAAAAAAAA VMRCXFTUEO\n",
      "AAAAAAAAAA WPCICCRABI\n",
      "AAAAAAAAAA WCDUKWROIL\n",
      "AAAAAAAAAA YRIOBWTIZP\n",
      "AAAAAAAAAA BAOPOJYRFJ\n",
      "AAAAAAAAAA UYCACLKBAA\n",
      "AAAAAAAAAA VKCTALQMGD\n",
      "AAAAAAAAAA ZSNYKLYAUI\n",
      "AAAAAAAAAA RLOCNQVDUI\n",
      "AAAAAAAAAA HYDMULWJLP\n",
      "AAAAAAAAAA QYABJBDOZD\n",
      "AAAAAAAAAA SVCMUDMGHQ\n",
      "AAAAAAAAAA ULBBSWJEYJ\n",
      "AAAAAAAAAA JOPALLCZMC\n",
      "AAAAAAAAAA IHCJMWJSMH\n",
      "AAAAAAAAAA QSCDITFZLZ\n",
      "AAAAAAAAAA KVEDZGCCXE\n",
      "AAAAAAAAAA PMURBQDTUM\n",
      "AAAAAAAAAA TIMZDIYFXP\n",
      "AAAAAAAAAA QHRNEUJSHE\n",
      "AAAAAAAAAA CDJHUESKJO\n",
      "AAAAAAAAAA VWVHGUAYSC\n",
      "AAAAAAAAAA JZCGBVVJTA\n",
      "AAAAAAAAAA ULGLBXBZFV\n",
      "AAAAAAAAAA GMVEBNYLVX\n",
      "AAAAAAAAAA WUCQCJWLZV\n",
      "AAAAAAAAAA QEPKTBBJIE\n",
      "AAAAAAAAAA YLALZBKNKU\n",
      "AAAAAAAAAA XOUZRYDCKF\n",
      "AAAAAAAAAA VGOQHKEMRV\n",
      "AAAAAAAAAA WEDKUWFSRH\n",
      "AAAAAAAAAA AHBVRXBXON\n",
      "AAAAAAAAAA MDGXRBBTEW\n",
      "AAAAAAAAAA RIVSSHNXMN\n",
      "AAAAAAAAAA ZVLSNAMZZF\n",
      "AAAAAAAAAA YJCIDQFDJN\n",
      "AAAAAAAAAA BUNBMUOUGV\n",
      "AAAAAAAAAA HPCFZCQMXT\n",
      "AAAAAAAAAA LBKABVELVL\n",
      "AAAAAAAAAA PWZYFWAMWQ\n",
      "AAAAAAAAAA SHBJWJWMAK\n",
      "AAAAAAAAAA GUPVPDKJVJ\n",
      "AAAAAAAAAA FMRHPCEYGQ\n",
      "AAAAAAAAAA SLNXDXYJIQ\n",
      "AAAAAAAAAA PZGBDKQSTF\n",
      "AAAAAAAAAA EYUGNCPOUD\n",
      "AAAAAAAAAA FQSARBZOSO\n",
      "AAAAAAAAAA JFNAUSOYMU\n"
     ]
    }
   ],
   "source": [
    "# Print predictions vs actual\n",
    "outputs = model.predict(test_inputs)\n",
    "for i in range(len(outputs)):\n",
    "    print(convert_index_vector(outputs[i]),convert_index_vector(test_outputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

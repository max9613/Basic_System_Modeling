{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Add as keras_add_layers\n",
    "from keras.callbacks import History\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static letter variable\n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "sequence_length = 10\n",
    "\n",
    "# Generates a random sequence of letters\n",
    "def generate_random_sequence_of_letters(length=sequence_length):\n",
    "    sequence = ''\n",
    "    for _ in range(length):\n",
    "        sequence += letters[rand.randint(0,len(letters) - 1)]\n",
    "    return sequence\n",
    "\n",
    "# Shifts the letters in a sequence by the specified amount\n",
    "def shift_sequence(sequence,shift_size=rand.randint(0,len(letters) - 2)):\n",
    "    ret_sequence = ''\n",
    "    for letter in sequence:\n",
    "        index = letters.index(letter)\n",
    "        index += shift_size\n",
    "        while index > len(letters) - 1:\n",
    "            index -= len(letters)\n",
    "        ret_sequence += letters[index]\n",
    "    return ret_sequence\n",
    "            \n",
    "# Converts a sequence of letters into an index vector\n",
    "def convert_to_index_vector(sequence):\n",
    "    ret_vector = []\n",
    "    for letter in sequence:\n",
    "        ret_vector.append(float(letters.index(letter)))\n",
    "    return ret_vector\n",
    "\n",
    "# Generates the scrambled inputs for a given sequence\n",
    "def generate_scrambled_inputs(sequence):\n",
    "    input_vector = convert_to_index_vector(shift_sequence(sequence,shift_size=12))\n",
    "    return input_vector\n",
    "\n",
    "# Converts a sequence to a hot vector sequence\n",
    "def convert_sequence_to_hot_vectors(sequence):\n",
    "    vectors = []\n",
    "    for num in sequence:\n",
    "        vector = np.zeros(len(letters))\n",
    "        vector[int(num)] = 1\n",
    "        vectors.append(vector)\n",
    "    return np.array(vectors)\n",
    "\n",
    "# Converts a hot vector sequence to a letter sequence\n",
    "def convert_hot_vectors_to_sequence(vectors):\n",
    "    indices = [np.argmax(vector) for vector in vectors]\n",
    "    return convert_index_vector(indices)\n",
    "\n",
    "# Generates training data\n",
    "def generate_training_data(size=10000):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for _ in range(size):\n",
    "        sequence = generate_random_sequence_of_letters()\n",
    "        outputs.append(convert_sequence_to_hot_vectors(convert_to_index_vector(sequence)))\n",
    "        inputs.append(convert_sequence_to_hot_vectors(generate_scrambled_inputs(sequence)))\n",
    "    return [np.array(inputs),np.array(outputs)]\n",
    "\n",
    "# Converts an index vector to a string\n",
    "def convert_index_vector(index_vector):\n",
    "    sequence = ''\n",
    "    for index in index_vector:\n",
    "        if round(index) < len(letters):\n",
    "            sequence += letters[int(round(index))]\n",
    "        else:\n",
    "            sequence += '*'\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(LSTM(len(letters),input_shape=(sequence_length,len(letters)),return_sequences=True))\n",
    "model.add(Dense(len(letters),activation='softmax'))\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual generation of training_data\n",
    "training_data = generate_training_data(10000)\n",
    "training_inputs = training_data[0]\n",
    "training_outputs = training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 3s 394us/step - loss: 0.1616 - acc: 0.9615 - val_loss: 0.1603 - val_acc: 0.9615\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.1590 - acc: 0.9615 - val_loss: 0.1573 - val_acc: 0.9615\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.1552 - acc: 0.9615 - val_loss: 0.1520 - val_acc: 0.9615\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.1468 - acc: 0.9615 - val_loss: 0.1380 - val_acc: 0.9615\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 2s 207us/step - loss: 0.1270 - acc: 0.9615 - val_loss: 0.1142 - val_acc: 0.9615\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.1025 - acc: 0.9615 - val_loss: 0.0892 - val_acc: 0.9616\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.0776 - acc: 0.9623 - val_loss: 0.0649 - val_acc: 0.9646\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.0548 - acc: 0.9752 - val_loss: 0.0445 - val_acc: 0.9898\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.0373 - acc: 0.9949 - val_loss: 0.0303 - val_acc: 0.9963\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.0257 - acc: 0.9966 - val_loss: 0.0214 - val_acc: 0.9972\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 0.0185 - acc: 0.9977 - val_loss: 0.0159 - val_acc: 0.9980\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.0141 - acc: 0.9981 - val_loss: 0.0123 - val_acc: 0.9981\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.0111 - acc: 0.9981 - val_loss: 0.0099 - val_acc: 0.9981\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.0091 - acc: 0.9981 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0069 - val_acc: 0.9981\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0052 - val_acc: 0.9987\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.0049 - acc: 0.9992 - val_loss: 0.0046 - val_acc: 0.9995\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.0043 - acc: 0.9997 - val_loss: 0.0041 - val_acc: 0.9998\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 0.0036 - val_acc: 0.9999\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 2s 263us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 2s 243us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 2s 263us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 2s 255us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 2s 254us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 3s 352us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 3s 373us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 3s 424us/step - loss: 9.7514e-04 - acc: 1.0000 - val_loss: 9.3916e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 4s 509us/step - loss: 9.0676e-04 - acc: 1.0000 - val_loss: 8.7418e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 3s 422us/step - loss: 8.4480e-04 - acc: 1.0000 - val_loss: 8.1521e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 7.8855e-04 - acc: 1.0000 - val_loss: 7.6170e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 2s 208us/step - loss: 7.3737e-04 - acc: 1.0000 - val_loss: 7.1293e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 6.9071e-04 - acc: 1.0000 - val_loss: 6.6840e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 2s 193us/step - loss: 6.4808e-04 - acc: 1.0000 - val_loss: 6.2770e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 6.0907e-04 - acc: 1.0000 - val_loss: 5.9040e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 2s 254us/step - loss: 5.7328e-04 - acc: 1.0000 - val_loss: 5.5616e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 5.4040e-04 - acc: 1.0000 - val_loss: 5.2465e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s 196us/step - loss: 5.1011e-04 - acc: 1.0000 - val_loss: 4.9560e-04 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 2s 198us/step - loss: 4.8218e-04 - acc: 1.0000 - val_loss: 4.6877e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 2s 204us/step - loss: 4.5636e-04 - acc: 1.0000 - val_loss: 4.4399e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 2s 195us/step - loss: 4.3246e-04 - acc: 1.0000 - val_loss: 4.2100e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 4.1030e-04 - acc: 1.0000 - val_loss: 3.9966e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 2s 257us/step - loss: 3.8971e-04 - acc: 1.0000 - val_loss: 3.7983e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 2s 272us/step - loss: 3.7055e-04 - acc: 1.0000 - val_loss: 3.6138e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s 261us/step - loss: 3.5271e-04 - acc: 1.0000 - val_loss: 3.4416e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s 244us/step - loss: 3.3606e-04 - acc: 1.0000 - val_loss: 3.2808e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s 242us/step - loss: 3.2050e-04 - acc: 1.0000 - val_loss: 3.1304e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s 245us/step - loss: 3.0594e-04 - acc: 1.0000 - val_loss: 2.9896e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 237us/step - loss: 2.9230e-04 - acc: 1.0000 - val_loss: 2.8576e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 2s 250us/step - loss: 2.7950e-04 - acc: 1.0000 - val_loss: 2.7337e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 2s 278us/step - loss: 2.6748e-04 - acc: 1.0000 - val_loss: 2.6172e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s 251us/step - loss: 2.5618e-04 - acc: 1.0000 - val_loss: 2.5076e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "6912/8000 [========================>.....] - ETA: 0s - loss: 2.4627e-04 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-68055f2fc060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training of the model\n",
    "history = model.fit(training_inputs,training_outputs,batch_size=256,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "test_data = generate_training_data(100)\n",
    "test_inputs = test_data[0]\n",
    "test_outputs = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have shape (10, 26) but got array with shape (20, 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c66ce5314c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print predictions vs actual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_hot_vectors_to_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconvert_hot_vectors_to_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(convert_index_vector(outputs[i]),convert_index_vector(test_outputs[i]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have shape (10, 26) but got array with shape (20, 26)"
     ]
    }
   ],
   "source": [
    "# Print predictions vs actual\n",
    "outputs = model.predict(test_inputs)\n",
    "for i in range(len(test_outputs)):\n",
    "    print(convert_hot_vectors_to_sequence(outputs[i]),convert_hot_vectors_to_sequence(test_outputs[i]))\n",
    "    #print(convert_index_vector(outputs[i]),convert_index_vector(test_outputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

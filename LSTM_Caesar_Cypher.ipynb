{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Add as keras_add_layers\n",
    "from keras.callbacks import History\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static letter variable\n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "sequence_length = 10\n",
    "\n",
    "# Generates a random sequence of letters\n",
    "def generate_random_sequence_of_letters(length=sequence_length):\n",
    "    sequence = ''\n",
    "    for _ in range(length):\n",
    "        sequence += letters[rand.randint(0,len(letters) - 1)]\n",
    "    return sequence\n",
    "\n",
    "# Shifts the letters in a sequence by the specified amount\n",
    "def shift_sequence(sequence,shift_size=rand.randint(0,len(letters) - 2)):\n",
    "    ret_sequence = ''\n",
    "    for letter in sequence:\n",
    "        index = letters.index(letter)\n",
    "        index += shift_size\n",
    "        while index > len(letters) - 1:\n",
    "            index -= len(letters)\n",
    "        ret_sequence += letters[index]\n",
    "    return ret_sequence\n",
    "            \n",
    "# Converts a sequence of letters into an index vector\n",
    "def convert_to_index_vector(sequence):\n",
    "    ret_vector = []\n",
    "    for letter in sequence:\n",
    "        ret_vector.append(float(letters.index(letter)))\n",
    "    return ret_vector\n",
    "\n",
    "# Generates the scrambled inputs for a given sequence\n",
    "def generate_scrambled_inputs(sequence):\n",
    "    input_vector = convert_to_index_vector(shift_sequence(sequence,shift_size=12))\n",
    "    return input_vector\n",
    "\n",
    "# Converts a sequence to a hot vector sequence\n",
    "def convert_sequence_to_hot_vectors(sequence):\n",
    "    vectors = []\n",
    "    for num in sequence:\n",
    "        vector = np.zeros(len(letters))\n",
    "        vector[int(num)] = 1\n",
    "        vectors.append(vector)\n",
    "    return np.array(vectors)\n",
    "\n",
    "# Converts a hot vector sequence to a letter sequence\n",
    "def convert_hot_vectors_to_sequence(vectors):\n",
    "    indices = [np.argmax(vector) for vector in vectors]\n",
    "    return convert_index_vector(indices)\n",
    "\n",
    "# Generates training data\n",
    "def generate_training_data(size=10000):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for _ in range(size):\n",
    "        sequence = generate_random_sequence_of_letters()\n",
    "        outputs.append(convert_sequence_to_hot_vectors(convert_to_index_vector(sequence)))\n",
    "        inputs.append(convert_sequence_to_hot_vectors(generate_scrambled_inputs(sequence)))\n",
    "    return [np.array(inputs),np.array(outputs)]\n",
    "\n",
    "# Converts an index vector to a string\n",
    "def convert_index_vector(index_vector):\n",
    "    sequence = ''\n",
    "    for index in index_vector:\n",
    "        if round(index) < len(letters):\n",
    "            sequence += letters[int(round(index))]\n",
    "        else:\n",
    "            sequence += '*'\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(LSTM(sequence_length,input_shape=(sequence_length,len(letters)),return_sequences=True))\n",
    "model.add(Dense(len(letters),activation='softmax'))\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual generation of training_data\n",
    "training_data = generate_training_data(10000)\n",
    "training_inputs = training_data[0]\n",
    "training_outputs = training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 3s 325us/step - loss: 0.1596 - acc: 0.9615 - val_loss: 0.1552 - val_acc: 0.9615\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 174us/step - loss: 0.1496 - acc: 0.9615 - val_loss: 0.1405 - val_acc: 0.9615\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 167us/step - loss: 0.1112 - acc: 0.9622 - val_loss: 0.0685 - val_acc: 0.9716\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 0.0417 - acc: 0.9881 - val_loss: 0.0224 - val_acc: 0.9925\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 169us/step - loss: 0.0165 - acc: 0.9941 - val_loss: 0.0123 - val_acc: 0.9961\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 164us/step - loss: 0.0103 - acc: 0.9962 - val_loss: 0.0084 - val_acc: 0.9962\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 0.0073 - acc: 0.9962 - val_loss: 0.0062 - val_acc: 0.9962\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 0.0055 - acc: 0.9978 - val_loss: 0.0048 - val_acc: 0.9996\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 168us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "1280/8000 [===>..........................] - ETA: 1s - loss: 0.0031 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-68055f2fc060>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\max9613\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training of the model\n",
    "history = model.fit(training_inputs,training_outputs,batch_size=256,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "test_data = generate_training_data(100)\n",
    "test_inputs = test_data[0]\n",
    "test_outputs = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWXMZLWRXI IWXMZLWRXI\n",
      "CYDHSNMNKE CYDHSNMNKE\n",
      "NZSNBZFGVY NZSNBZFGVY\n",
      "OGMGXIMIVJ OGMGXIMIVJ\n",
      "ZLCLNFMFTZ ZLCLNFMFTZ\n",
      "WJJVZDGBUV WJJVZDGBUV\n",
      "VPLYAHHDEM VPLYAHHDEM\n",
      "LJBJJBCVPS LJBJJBCVPS\n",
      "MUDNODCHKL MUDNODCHKL\n",
      "CCCYYASFVB CCCYYASFVB\n",
      "JBZMFLRMDP JBZMFLRMDP\n",
      "JXCHOKEUVX JXCHOKEUVX\n",
      "QKPJXDHQOG QKPJXDHQOG\n",
      "UOCFOIKPAE UOCFOIKPAE\n",
      "BYKQZYHTSX BYKQZYHTSX\n",
      "SPGDRYDSVD SPGDRYDSVD\n",
      "JALTMULKFL JALTMULKFL\n",
      "QYQUHZQMUI QYQUHZQMUI\n",
      "PYCMNKJTZU PYCMNKJTZU\n",
      "BZVAZTOSXF BZVAZTOSXF\n",
      "EKTEVVVSSD EKTEVVVSSD\n",
      "BRWPXTVDZY BRWPXTVDZY\n",
      "VHPAYZYIWG VHPAYZYIWG\n",
      "DMNENSWQWI DMNENSWQWI\n",
      "ITBEQUYLEP ITBEQUYLEP\n",
      "LDXDUJWLMT LDXDUJWLMT\n",
      "RNBLTHEKDH RNBLTHEKDH\n",
      "DACZSJUZSK DACZSJUZSK\n",
      "IZAIFJYYEF IZAIFJYYEF\n",
      "PCASKXFXBP PCASKXFXBP\n",
      "QWXDSEQFCY QWXDSEQFCY\n",
      "QNVKCUOKQA QNVKCUOKQA\n",
      "NNEXATPOXL NNEXATPOXL\n",
      "DWVKSWXWEA DWVKSWXWEA\n",
      "WILOPAORRK WILOPAORRK\n",
      "DJHOPWGVRK DJHOPWGVRK\n",
      "RZRRSCSEIA RZRRSCSEIA\n",
      "BQJICCZLHD BQJICCZLHD\n",
      "MBNJNBRUQK MBNJNBRUQK\n",
      "ZKKJSLIIBG ZKKJSLIIBG\n",
      "KDCGVCOMLC KDCGVCOMLC\n",
      "MVVWADIZQL MVVWADIZQL\n",
      "ASNVZSYOXG ASNVZSYOXG\n",
      "QPRSWNAPRZ QPRSWNAPRZ\n",
      "UQZGWUAWWK UQZGWUAWWK\n",
      "ECNAFJFJBO ECNAFJFJBO\n",
      "AIOGMRICEI AIOGMRICEI\n",
      "BRXVXSISZI BRXVXSISZI\n",
      "KMKFATGQPS KMKFATGQPS\n",
      "KFIGGZIZLM KFIGGZIZLM\n",
      "TPYUJHJVHD TPYUJHJVHD\n",
      "UPHJGNCWUI UPHJGNCWUI\n",
      "RAFQRKNMSQ RAFQRKNMSQ\n",
      "NUHLYZNCQU NUHLYZNCQU\n",
      "BGQQBVBEHU BGQQBVBEHU\n",
      "UYOALMCUTM UYOALMCUTM\n",
      "SNMYMERTCF SNMYMERTCF\n",
      "EXFBKVSIUO EXFBKVSIUO\n",
      "PGCOXJTYLY PGCOXJTYLY\n",
      "EJSKJQNYIF EJSKJQNYIF\n",
      "FRLTGPMKNQ FRLTGPMKNQ\n",
      "RWCOFPLDSX RWCOFPLDSX\n",
      "LSZSTRJNZX LSZSTRJNZX\n",
      "UTFKOJPNAP UTFKOJPNAP\n",
      "WDIOMGPNJV WDIOMGPNJV\n",
      "DQYFHALLNY DQYFHALLNY\n",
      "BKCLRHBUDN BKCLRHBUDN\n",
      "WEMKKUCZUJ WEMKKUCZUJ\n",
      "ZRDDVPCMWK ZRDDVPCMWK\n",
      "HZSNLHYLHS HZSNLHYLHS\n",
      "RPZLPRARLC RPZLPRARLC\n",
      "LVXVVTLPYB LVXVVTLPYB\n",
      "ZPDIDZGBJT ZPDIDZGBJT\n",
      "WBENBTFGZY WBENBTFGZY\n",
      "OQVUMXEMWA OQVUMXEMWA\n",
      "YRKVRCFWRO YRKVRCFWRO\n",
      "KMLFWJNMRH KMLFWJNMRH\n",
      "UXAUJXUBBH UXAUJXUBBH\n",
      "EWHCFASCSM EWHCFASCSM\n",
      "RCTGBVGPWL RCTGBVGPWL\n",
      "XUSLFPBWCO XUSLFPBWCO\n",
      "WWZXGZLIHT WWZXGZLIHT\n",
      "NIVKHRPEXT NIVKHRPEXT\n",
      "JWPLBTSBCV JWPLBTSBCV\n",
      "DPTYWPYBGZ DPTYWPYBGZ\n",
      "QZZAAKZNAU QZZAAKZNAU\n",
      "CDARWGVNVK CDARWGVNVK\n",
      "KFLTRUWPXR KFLTRUWPXR\n",
      "JDYXEWDTBS JDYXEWDTBS\n",
      "NBSINYWPTZ NBSINYWPTZ\n",
      "TTCKWICFZR TTCKWICFZR\n",
      "DXXNWPIDFM DXXNWPIDFM\n",
      "HNICYFZXXF HNICYFZXXF\n",
      "CKANXPTGKQ CKANXPTGKQ\n",
      "DXYJZGQBJT DXYJZGQBJT\n",
      "CDOKZQDRFK CDOKZQDRFK\n",
      "DEOWKPSNZO DEOWKPSNZO\n",
      "PLZNDFREMI PLZNDFREMI\n",
      "YJJLOMLJUA YJJLOMLJUA\n",
      "KUDXWINCQK KUDXWINCQK\n"
     ]
    }
   ],
   "source": [
    "# Print predictions vs actual\n",
    "outputs = model.predict(test_inputs)\n",
    "for i in range(len(test_outputs)):\n",
    "    print(convert_hot_vectors_to_sequence(outputs[i]),convert_hot_vectors_to_sequence(test_outputs[i]))\n",
    "    #print(convert_index_vector(outputs[i]),convert_index_vector(test_outputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
